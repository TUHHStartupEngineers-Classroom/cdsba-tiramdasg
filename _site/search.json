[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website every time before you want to upload changes."
  },
  {
    "objectID": "content/01_journal/02_statistics.html",
    "href": "content/01_journal/02_statistics.html",
    "title": "Statistical Concepts",
    "section": "",
    "text": "Part 1\nFor each variable, compute the following values. You can use the built-in functions or use the mathematical formulas.\n\nExpected Value\nVariance\nStandard Deviation\n\n\nrandom_vars &lt;- readRDS(\"../../Causal_Data_Science_Data/random_vars.rds\")\n\n# part 1\nexpected_value_age &lt;- mean(random_vars$age)\nexpected_value_income &lt;- mean(random_vars$income)\n\nvariance_age &lt;- var(random_vars$age)\nvariance_income &lt;- var(random_vars$income)\n\nstd_dev_age &lt;- sd(random_vars$age)\nstd_dev_income &lt;- sd(random_vars$income)\n\ncat(\"Expected Values \\nAge: \", expected_value_age,\"\\nIncome: \", expected_value_income)\n\n#&gt; Expected Values \n#&gt; Age:  33.471 \n#&gt; Income:  3510.731\n\ncat(\"Variance \\nAge: \", variance_age,\"\\nIncome: \", variance_income)\n\n#&gt; Variance \n#&gt; Age:  340.6078 \n#&gt; Income:  8625646\n\ncat(\"Standard Deviation \\nAge: \", std_dev_age,\"\\nIncome: \", std_dev_income)\n\n#&gt; Standard Deviation \n#&gt; Age:  18.45556 \n#&gt; Income:  2936.945\n\n\n\n\nPart 2\nExplain, if it makes sense to compare the standard deviations.\n\nStandard deviation measures the spread or variability of a distribution. If one variable has a much larger standard deviation than another, it indicates greater variability in the data points.\nComparing standard deviations makes sense if the variables are measured in same units. In this example one is age in years and another is salary in currency. Therefore, it is not meaningful in this example to compare standard deviations directly.\n\n\n\nPart 3\nThen, examine the relationship between both variables and compute: covariance and correlation\n\nCovariance is a measure of how 2 variables vary together. If positive, it suggests that higher values of one variable are associated with higher variables of the other, and vice versa if negative covariance.\nCorrelation is a standardized measure that indicates the strength and direction of a linear relationship between 2 variables. Ranges from -1 to 1, where -1 indicates a perfect negative linear relationship, +1 indicates a perfect positive linear relationship, and 0 indicates no linear relationship.\n\n\ncovar_age_income &lt;- cov(random_vars$age, random_vars$income)\ncorr_age_income &lt;- cor(random_vars$age, random_vars$income)\n\ncat(\"Covariance: \", covar_age_income, \"\\nCorrelation: \", corr_age_income)\n\n#&gt; Covariance:  29700.15 \n#&gt; Correlation:  0.5479432\n\n\n\n\nPart 4\nWhat measure is easier to interpret? Please discuss your interpretation.\nFrom above we see from the value of Covariance is too large and hard to interpret how the variables age and income vary with respect to each other.\nAs correlation is standardized, ranging from -1 to 1, it is easier to compare the strength and direction of relationships between variables, regardless of the scale or units.\nHere, correlation is positive with a value of approximately 0.5479, implying a positive linear relationship between age and income.\n\n\nPart 5\nCompute the conditional expected values for:\n\nE[income | age &lt;= 18]\nE[income | age \\(\\in\\) [18, 65)]\nE[income | age &gt;= 65]\n\n\nlibrary(dplyr)\n\n#&gt; \n#&gt; Attaching package: 'dplyr'\n\n\n#&gt; The following objects are masked from 'package:stats':\n#&gt; \n#&gt;     filter, lag\n\n\n#&gt; The following objects are masked from 'package:base':\n#&gt; \n#&gt;     intersect, setdiff, setequal, union\n\nrandom_vars &lt;- random_vars %&gt;%\n  filter(!is.na(income), !is.na(age))\n\ncond_exp_income_age_18 &lt;- random_vars %&gt;%\n  filter(age &lt;= 18) %&gt;%\n  summarise(mean_income = mean(income)) %&gt;%\n  pull(mean_income)\n\ncond_exp_income_age_18_65 &lt;- random_vars %&gt;%\n  filter(age &gt;= 18, age &lt; 65) %&gt;%\n  summarise(mean_income = mean(income)) %&gt;%\n  pull(mean_income)\n\ncond_exp_income_age_65 &lt;- random_vars %&gt;%\n  filter(age &gt;= 65) %&gt;%\n  summarise(mean_income = mean(income)) %&gt;%\n  pull(mean_income)\n\ncat(\"18 and below: \", cond_exp_income_age_18, \"\\n18 and 65: \", cond_exp_income_age_18_65, \"\\n65 above: \", cond_exp_income_age_65)\n\n#&gt; 18 and below:  389.6074 \n#&gt; 18 and 65:  4685.734 \n#&gt; 65 above:  1777.237"
  },
  {
    "objectID": "content/01_journal/04_causality.html",
    "href": "content/01_journal/04_causality.html",
    "title": "Causality",
    "section": "",
    "text": "Spurious Correlation example.\nLoading the required libraries:\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n#&gt; \n#&gt; Attaching package: 'dplyr'\n\n\n#&gt; The following objects are masked from 'package:stats':\n#&gt; \n#&gt;     filter, lag\n\n\n#&gt; The following objects are masked from 'package:base':\n#&gt; \n#&gt;     intersect, setdiff, setequal, union\n\n\nSet seed for reproducability\n\nset.seed(210)\n\nThe following code has the following:\n\nSimulation Function (simulate_ar):\n\nsimulate_ar function generates a time series of length n with an auto-regressive structure defined by the parameter \\(\\phi\\).\nThe auto-regressive process is simulated with the formula \\(Y_t = \\phi \\cdot Y_{t-1} + \\epsilon_t\\), where \\(\\epsilon_t\\) is a normally distributed random error with mean 0 and standard deviation sigma.\n\nSimulation and Testing Loop:\n\nSet up a grid of combinations for times, n, and phis using “expand.grid”.\nIterates over each combination and performs a correlation test between two time series generated with the same auto-regressive structure but different random noise.\nThe results are stored as matrix res.\n\nData Manipulation with dplyr:\n\nres converted to a data frame (dat) grouped by the phi values, and summary statistics (average absolute correlation, average absolute t-statistic, and the percentage of statistically significant p-values).\n\n\n\nn &lt;- 500\ntimes &lt;- 100\nphis &lt;- seq(0, 1, .02)\ncomb &lt;- expand.grid(times = seq(times), n = n, phis)\nncomb &lt;- nrow(comb)\n\nres &lt;- matrix(NA, nrow = ncomb, ncol = 6)\ncolnames(res) &lt;- c('ix', 'n', 'phi', 'cor', 'tstat', 'pval')\n\nsimulate_ar &lt;- function(n, phi, sigma = .1) {\n  y &lt;- rep(0, n)\n  \n  for (t in seq(2, n)) {\n    y[t] &lt;- phi*y[t-1] + rnorm(1, 0, sigma)\n  }\n  \n  y\n}\n\nfor (i in seq(ncomb)) {\n  ix &lt;- comb[i, 1]\n  n &lt;- comb[i, 2]\n  phi &lt;- comb[i, 3]\n  \n  test &lt;- cor.test(simulate_ar(n, phi = phi), simulate_ar(n, phi = phi))\n  res[i, ] &lt;- c(ix, n, phi, test$estimate, test$statistic, test$p.value)\n}\n\ndat &lt;- data.frame(res) %&gt;% \n  group_by(phi) %&gt;% \n  summarize(\n    avg_abs_corr = mean(abs(cor)),\n    avg_abs_tstat = mean(abs(tstat)),\n    percent_sig = mean(pval &lt; .05)\n  )\n\n\nggplot(dat, aes(x = phi, y = percent_sig)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"green\") +\n  labs(title = \"Spurious Correlation: phi vs Avg Abs Correlation\",\n       x = \"X - Phi\",\n       y = \"Y - Avg Abs Correlation\") +\n  theme_minimal()\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe plot shows a scatter plot with a linear regression line, and visualizes the average absolute correlation against the phi values. It helps in understanding how the strength of the spurious correlation varies with different values of the auto-regressive parameter phi."
  },
  {
    "objectID": "content/01_journal/09_iv.html",
    "href": "content/01_journal/09_iv.html",
    "title": "Instrumental Variables",
    "section": "",
    "text": "library(dplyr)\n\n#&gt; \n#&gt; Attaching package: 'dplyr'\n\n\n#&gt; The following objects are masked from 'package:stats':\n#&gt; \n#&gt;     filter, lag\n\n\n#&gt; The following objects are masked from 'package:base':\n#&gt; \n#&gt;     intersect, setdiff, setequal, union\n\nlibrary(dagitty)\nlibrary(ggdag)\n\n#&gt; \n#&gt; Attaching package: 'ggdag'\n\n\n#&gt; The following object is masked from 'package:stats':\n#&gt; \n#&gt;     filter\n\nlibrary(ggrepel)\n\n#&gt; Loading required package: ggplot2\n\ndf &lt;- readRDS(\"../../Causal_Data_Science_Data/rand_enc.rds\")\n\n# Part 1\niv_expl &lt;- dagify(\n  Y ~ D,\n  Y ~ U,\n  D ~ U,\n  D ~ Z,\n  exposure = \"D\",\n  latent = \"U\",\n  outcome = \"Y\",\n  coords = list(x = c(U = 1, D = 0, Y = 2, Z = -1),\n                y = c(U = 1, D = 0, Y = 0, Z = 0)),\n  labels = c(\"D\" = \"Used New Features\",\n             \"Y\" = \"Time Spent\",\n             \"U\" = \"Unobserved Characteristics\",\n             \"Z\" = \"Random Encouragement\")\n)\n\n# Plot the DAG\nggdag(iv_expl, text = TRUE) +\n  geom_dag_point(color = \"lightblue\") +\n  geom_dag_text(color = \"white\") +\n  geom_dag_edges(edge_color = \"white\") +\n  geom_dag_label_repel(aes(label = label)) +\n  theme(panel.background = element_rect(fill = \"black\"))"
  },
  {
    "objectID": "content/01_journal/07_matching.html",
    "href": "content/01_journal/07_matching.html",
    "title": "Matching and Subclassification",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/05_dag.html",
    "href": "content/01_journal/05_dag.html",
    "title": "Directed Acyclic Graphs",
    "section": "",
    "text": "Example from previous chapter (parking spots) and draw the DAG.\nIn this DAG:\n\nLocation is the treatment variable (whether the store is in the city center or outside the city).\nParkingSpots is the variable representing whether the store has parking spots or not.\nSales is the outcome variable (sales of the store).\n\nThe arrows in the DAG indicate the causal relationships between the variables. For example, there is an arrow from Location to ParkingSpots indicating that the location influences the availability of parking spots.\n\n# Load necessary packages\nlibrary(dagitty)\nlibrary(ggdag)\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks ggdag::filter(), stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Part 1 \ndag &lt;- dagitty(\"dag {\n  ParkingSpots -&gt; Sales\n  Location -&gt; ParkingSpots\n  Location -&gt; Sales\n}\")\n\nplot(dag)\n\n#&gt; Plot coordinates for graph not supplied! Generating coordinates, see ?coordinates for how to set your own.\n\n\n\n\n\n\n\n\n# Draw DAG\nggdag(dag)"
  },
  {
    "objectID": "content/01_journal/06_rct.html",
    "href": "content/01_journal/06_rct.html",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/08_did.html",
    "href": "content/01_journal/08_did.html",
    "title": "Difference-in-Differences",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/01_probability.html",
    "href": "content/01_journal/01_probability.html",
    "title": "Probability Theory",
    "section": "",
    "text": "Assignment 1\nFrom the picture: \nWe know:\nP(S) = 0.3\nP(T) = 0.7\nP(T | S) = 0.2\nP(T | S) = 0.8\nP(T | S) = 0.6\nP(T | S) = 0.4\nReferring to \nThe solutions:\n\nP(T ∩ S) = P(S) * P(T | S)\nP(T ∩ S) = P(S) * P(T | S)\nP(T ∩ S) = P(S) * P(T | S)\nP(T ∩ S) = P(S) * P(T | S)\n\n\nS &lt;- 0.3\nTgS &lt;- 0.2 # 0.8 is Tbar given S\nTgSbar &lt;- 0.6 # 0.4 is Tbar given Sbar\n\nTandS &lt;- S * TgS\nTandSbar &lt;- (1 - S) * TgSbar\nTbarandS &lt;- S * (1 - TgS)\nTbarandSbar &lt;- (1 - S) * (1 - TgSbar)\n\nprint( paste( \"Sum: \", ( TandS + TandSbar + TbarandS + TbarandSbar ) ) )\n\n#&gt; [1] \"Sum:  1\"\n\n\n\n\nAssignment 2\n\n\n\nFigure 1: Venn Diagram\n\n\nFrom the venn diagram:\n\nThe percentage of customers using all three devices is\n\n5 or 0.5% of total customers\n\nThe percentage of customers using at least 2 devices\n\nCustomers using (Smartphones and Tablets) + (Tablet and Computer) + (Computer and Smartphone) + (all three)\n199 or 19.9% of customers\n\nThe percentage of customers using only one device\n\nCustomers using only smartphone + only Tablet + only computer\n801 or 80.1% of customers\n\n\n\n\nAssignment 3\nGiven:\n\nP(A) = 0.04\nP(B|A) = 0.97\nP(B|A) = 0.01\n\nTo find P(A|B) and P(A|B)\n\nCalculate P(B): \\[\nP(B) = P(B|A) \\cdot P(A) + P(B|\\overline{A}) \\cdot P(\\overline{A})\n\\]\n\n\\[\nP(B) = 0.97 \\cdot 0.04 + 0.01 \\cdot (1 - 0.04) \\\\\n\\]\n\\[\nP(B) = 0.0484\n\\] 2. Apply Bayes’ Theorem:\n\\[\nP(A | B) = \\frac{P(B | A) \\cdot P(A)}{P(B)} \\\\\n\\]\n\\[\nP (A | B) = \\frac{0.97 \\cdot 0.04}{0.0484}\\\\\n\\]\n\\[\nP(A | B) = 0.791\n\\] Similarly, \\[\nP(\\overline{A} | B) = \\frac{P(B | \\overline{A}) \\cdot P(\\overline{A})}{P(B)} \\\\\n\\] \\[\nP (\\overline{A} | B) = \\frac{0.01 \\cdot (1 - 0.04)}{0.0484}\\\\\n\\] \\[\nP(\\overline{A} | B) = 0.209\n\\]\nNow subsituting the values to the sentence:\n“These results show that in case the alarm is triggered, there is a probability of about 79.1% that the product is flawless and a probability of about 20.9% that the product is faulty”."
  },
  {
    "objectID": "content/01_journal/01_probability.html#header-2",
    "href": "content/01_journal/01_probability.html#header-2",
    "title": "Probability Theory",
    "section": "2.1 Header 2",
    "text": "2.1 Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  },
  {
    "objectID": "content/01_journal/03_regression.html",
    "href": "content/01_journal/03_regression.html",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "Part 1\nRead the data and check the dimensions. How many rows and how many columns does the data have? You could use e.g. the dim() command.\n\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# 1\n\ncar_data &lt;- readRDS(\"../../Causal_Data_Science_Data/car_prices.rds\")\ncar_data &lt;- na.omit(car_data)\ncat(\"Dimensions of the data:\", dim(car_data), \"\\n\")\n\n#&gt; Dimensions of the data: 181 22\n\n\n\n\nPart 2\nUse appropriate commands to get a more detailed look at the data. What data types do you see? How do numbers differ from strings regarding their data type?\n\n# 2\n\nsummary(car_data) # may also use str(car_data)\n\n#&gt;   aspiration         doornumber          carbody           drivewheel       \n#&gt;  Length:181         Length:181         Length:181         Length:181        \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;  enginelocation       wheelbase        carlength        carwidth    \n#&gt;  Length:181         Min.   : 86.60   Min.   :141.1   Min.   :60.30  \n#&gt;  Class :character   1st Qu.: 94.50   1st Qu.:166.3   1st Qu.:64.00  \n#&gt;  Mode  :character   Median : 96.50   Median :173.0   Median :65.40  \n#&gt;                     Mean   : 98.21   Mean   :173.3   Mean   :65.74  \n#&gt;                     3rd Qu.:100.40   3rd Qu.:180.2   3rd Qu.:66.50  \n#&gt;                     Max.   :120.90   Max.   :208.1   Max.   :72.30  \n#&gt;    carheight       curbweight    enginetype        cylindernumber    \n#&gt;  Min.   :47.80   Min.   :1488   Length:181         Length:181        \n#&gt;  1st Qu.:52.00   1st Qu.:2122   Class :character   Class :character  \n#&gt;  Median :53.70   Median :2410   Mode  :character   Mode  :character  \n#&gt;  Mean   :53.58   Mean   :2521                                        \n#&gt;  3rd Qu.:55.50   3rd Qu.:2910                                        \n#&gt;  Max.   :59.80   Max.   :4066                                        \n#&gt;    enginesize     fuelsystem          boreratio         stroke    \n#&gt;  Min.   : 61.0   Length:181         Min.   :2.540   Min.   :2.07  \n#&gt;  1st Qu.: 98.0   Class :character   1st Qu.:3.150   1st Qu.:3.08  \n#&gt;  Median :120.0   Mode  :character   Median :3.310   Median :3.23  \n#&gt;  Mean   :127.1                      Mean   :3.325   Mean   :3.23  \n#&gt;  3rd Qu.:141.0                      3rd Qu.:3.590   3rd Qu.:3.40  \n#&gt;  Max.   :326.0                      Max.   :3.940   Max.   :4.17  \n#&gt;  compressionratio   horsepower       peakrpm        citympg     \n#&gt;  Min.   : 7.000   Min.   : 48.0   Min.   :4200   Min.   :13.00  \n#&gt;  1st Qu.: 8.500   1st Qu.: 70.0   1st Qu.:4800   1st Qu.:19.00  \n#&gt;  Median : 9.000   Median : 95.0   Median :5200   Median :24.00  \n#&gt;  Mean   : 8.848   Mean   :106.2   Mean   :5182   Mean   :24.85  \n#&gt;  3rd Qu.: 9.400   3rd Qu.:116.0   3rd Qu.:5500   3rd Qu.:30.00  \n#&gt;  Max.   :11.500   Max.   :288.0   Max.   :6600   Max.   :49.00  \n#&gt;    highwaympg        price      \n#&gt;  Min.   :16.00   Min.   : 5118  \n#&gt;  1st Qu.:25.00   1st Qu.: 7609  \n#&gt;  Median :30.00   Median : 9980  \n#&gt;  Mean   :30.48   Mean   :12999  \n#&gt;  3rd Qu.:34.00   3rd Qu.:16430  \n#&gt;  Max.   :54.00   Max.   :45400\n\nhead(car_data)\n\n\n\n  \n\n\n\nHas 22 Variables with\naspiration, doornumber, carbody, drivewheel, enginelocation, enginetype, cylindernumber, fuelsystem with character values,\nand wheelbase, carlength, carwidth, carheight, curbweight, enginesize, boreratio, stroke, compressionratio, horsepower, peakrpm, citympg, highwaympg, price with numeric values.\n\n\nPart 3\nRun a linear regression. You want to explain what factors are relevant for the pricing of a car.\n\n# 3\ncar_model &lt;- lm(price ~ doornumber + carbody + enginetype + fuelsystem + stroke + horsepower + citympg, data = car_data)\nsummary(car_model)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ doornumber + carbody + enginetype + fuelsystem + \n#&gt;     stroke + horsepower + citympg, data = car_data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8922.8 -1774.7   -15.5  1466.0 16355.9 \n#&gt; \n#&gt; Coefficients:\n#&gt;                  Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)       4992.75    6211.58   0.804 0.422701    \n#&gt; doornumbertwo     -539.74     902.44  -0.598 0.550614    \n#&gt; carbodyhardtop   -3617.15    2267.11  -1.595 0.112551    \n#&gt; carbodyhatchback -6461.38    1753.77  -3.684 0.000312 ***\n#&gt; carbodysedan     -4771.37    1848.61  -2.581 0.010736 *  \n#&gt; carbodywagon     -6128.24    2032.18  -3.016 0.002978 ** \n#&gt; enginetypedohcv  -9993.95    4639.52  -2.154 0.032711 *  \n#&gt; enginetypel       4884.77    2028.64   2.408 0.017168 *  \n#&gt; enginetypeohc     3202.33    1323.44   2.420 0.016640 *  \n#&gt; enginetypeohcf    1565.76    1759.84   0.890 0.374935    \n#&gt; enginetypeohcv    2557.31    1602.92   1.595 0.112570    \n#&gt; fuelsystem2bbl    -153.25    1314.25  -0.117 0.907316    \n#&gt; fuelsystemmfi    -7560.37    4217.62  -1.793 0.074908 .  \n#&gt; fuelsystemmpfi   -1676.81    1515.73  -1.106 0.270251    \n#&gt; fuelsystemspdi   -6473.78    1931.46  -3.352 0.000999 ***\n#&gt; fuelsystemspfi     452.35    4125.97   0.110 0.912835    \n#&gt; stroke            -697.37    1245.17  -0.560 0.576210    \n#&gt; horsepower         173.88      16.93  10.268  &lt; 2e-16 ***\n#&gt; citympg           -166.47      96.59  -1.723 0.086716 .  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3879 on 162 degrees of freedom\n#&gt; Multiple R-squared:  0.792,  Adjusted R-squared:  0.7689 \n#&gt; F-statistic: 34.27 on 18 and 162 DF,  p-value: &lt; 2.2e-16\n\n\nWith some limited knowledge about cars, I think the factors mentioned above are relevant to a car price. I will use horsepower for further analysis.\n\n\nPart 4\nChoose one regressor and\n\nexplain what data type it is and what values it can take on\nwhat effect it has on the price and what changing the value would have as a result\nwhether its effect is statistically significant.\n\nChoosing “horsepower”\n\n# 4\n\n# data type it is and what values it can take on\nstr(car_data$horsepower)\n\n#&gt;  num [1:181] 111 111 154 102 115 110 110 110 140 160 ...\n\n# effect it has on the price and what changing the value would have as a result\nsummary(car_model)$coefficients['horsepower',]\n\n#&gt;     Estimate   Std. Error      t value     Pr(&gt;|t|) \n#&gt; 1.311579e+02 1.480934e+01 8.856434e+00 1.669974e-15\n\n# statistically significant\nsummary(car_model)$coefficients['horsepower','Pr(&gt;|t|)']\n\n#&gt; [1] 1.669974e-15\n\n\n\n\nPart 5\nAdd a variable seat_heating to the data and assign a value TRUE for all observations. You can use e.g. df %&gt;% mutate(new_variable = value). Assign it to a new object and run a regression. What coefficient do you get for the new variable seat_heating and how can you explain it?\n\n# 5\n\n# Add variable 'seat_heating' and run a regression\ncar_prices_new &lt;- car_data %&gt;%\n  mutate(seat_heating = TRUE) %&gt;%\n  na.omit()\n\n# Run a regression with the new variable\nmodel_new &lt;- lm(price ~ doornumber + carbody + enginetype + fuelsystem + stroke + horsepower + citympg + seat_heating, data = car_prices_new)\n\nsummary(car_prices_new$seat_heating)\n\n#&gt;    Mode    TRUE \n#&gt; logical     181\n\nsummary(model_new)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ doornumber + carbody + enginetype + fuelsystem + \n#&gt;     stroke + horsepower + citympg + seat_heating, data = car_prices_new)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8922.8 -1774.7   -15.5  1466.0 16355.9 \n#&gt; \n#&gt; Coefficients: (1 not defined because of singularities)\n#&gt;                  Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)       4992.75    6211.58   0.804 0.422701    \n#&gt; doornumbertwo     -539.74     902.44  -0.598 0.550614    \n#&gt; carbodyhardtop   -3617.15    2267.11  -1.595 0.112551    \n#&gt; carbodyhatchback -6461.38    1753.77  -3.684 0.000312 ***\n#&gt; carbodysedan     -4771.37    1848.61  -2.581 0.010736 *  \n#&gt; carbodywagon     -6128.24    2032.18  -3.016 0.002978 ** \n#&gt; enginetypedohcv  -9993.95    4639.52  -2.154 0.032711 *  \n#&gt; enginetypel       4884.77    2028.64   2.408 0.017168 *  \n#&gt; enginetypeohc     3202.33    1323.44   2.420 0.016640 *  \n#&gt; enginetypeohcf    1565.76    1759.84   0.890 0.374935    \n#&gt; enginetypeohcv    2557.31    1602.92   1.595 0.112570    \n#&gt; fuelsystem2bbl    -153.25    1314.25  -0.117 0.907316    \n#&gt; fuelsystemmfi    -7560.37    4217.62  -1.793 0.074908 .  \n#&gt; fuelsystemmpfi   -1676.81    1515.73  -1.106 0.270251    \n#&gt; fuelsystemspdi   -6473.78    1931.46  -3.352 0.000999 ***\n#&gt; fuelsystemspfi     452.35    4125.97   0.110 0.912835    \n#&gt; stroke            -697.37    1245.17  -0.560 0.576210    \n#&gt; horsepower         173.88      16.93  10.268  &lt; 2e-16 ***\n#&gt; citympg           -166.47      96.59  -1.723 0.086716 .  \n#&gt; seat_heatingTRUE       NA         NA      NA       NA    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3879 on 162 degrees of freedom\n#&gt; Multiple R-squared:  0.792,  Adjusted R-squared:  0.7689 \n#&gt; F-statistic: 34.27 on 18 and 162 DF,  p-value: &lt; 2.2e-16\n\n\nAs seen in summary of regression model “seat_heatingTRUE” with NA is what we get - indicates that this categorical variable (seat_heating) has only one level, that is value “TRUE”. This is proved with summary statement above this."
  },
  {
    "objectID": "content/01_journal/10_rdd.html",
    "href": "content/01_journal/10_rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/02_statistics.html#header-2",
    "href": "content/01_journal/02_statistics.html#header-2",
    "title": "Statistical Concepts",
    "section": "2.1 Header 2",
    "text": "2.1 Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  },
  {
    "objectID": "content/01_journal/05_dag.html#part-1",
    "href": "content/01_journal/05_dag.html#part-1",
    "title": "Directed Acyclic Graphs",
    "section": "",
    "text": "Example from previous chapter (parking spots) and draw the DAG.\nIn this DAG:\n\nLocation is the treatment variable (whether the store is in the city center or outside the city).\nParkingSpots is the variable representing whether the store has parking spots or not.\nSales is the outcome variable (sales of the store).\n\nThe arrows in the DAG indicate the causal relationships between the variables. For example, there is an arrow from Location to ParkingSpots indicating that the location influences the availability of parking spots.\n\n# Load necessary packages\nlibrary(dagitty)\nlibrary(ggdag)\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks ggdag::filter(), stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Part 1 \ndag &lt;- dagitty(\"dag {\n  ParkingSpots -&gt; Sales\n  Location -&gt; ParkingSpots\n  Location -&gt; Sales\n}\")\n\nplot(dag)\n\n#&gt; Plot coordinates for graph not supplied! Generating coordinates, see ?coordinates for how to set your own.\n\n\n\n\n\n\n\n\n# Draw DAG\nggdag(dag)"
  },
  {
    "objectID": "content/01_journal/05_dag.html#part-2",
    "href": "content/01_journal/05_dag.html#part-2",
    "title": "Directed Acyclic Graphs",
    "section": "Part 2",
    "text": "Part 2\nUsing lm function as linear regression model. summary to display detailed information about regression models.\n\ncust_sat &lt;- readRDS(\"../../Causal_Data_Science_Data/customer_sat.rds\")\n\n# 1. regress satisfaction on follow_ups\nmodel1 &lt;- lm(satisfaction ~ follow_ups, data = cust_sat)\nsummary(model1)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups, data = cust_sat)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -12.412  -5.257   1.733   4.506  12.588 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  78.8860     4.2717  18.467 1.04e-10 ***\n#&gt; follow_ups   -3.3093     0.6618  -5.001 0.000243 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 7.923 on 13 degrees of freedom\n#&gt; Multiple R-squared:  0.658,  Adjusted R-squared:  0.6316 \n#&gt; F-statistic: 25.01 on 1 and 13 DF,  p-value: 0.0002427\n\n# 2. regress satisfaction on follow_ups and account for subscription\nmodel2 &lt;- lm(satisfaction ~ follow_ups + subscription, data = cust_sat)\nsummary(model2)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups + subscription, data = cust_sat)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -4.3222 -2.1972  0.3167  2.2667  3.9944 \n#&gt; \n#&gt; Coefficients:\n#&gt;                      Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)           26.7667     6.6804   4.007  0.00206 ** \n#&gt; follow_ups             2.1944     0.7795   2.815  0.01682 *  \n#&gt; subscriptionPremium   44.7222     5.6213   7.956 6.88e-06 ***\n#&gt; subscriptionPremium+  18.0722     2.1659   8.344 4.37e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2.958 on 11 degrees of freedom\n#&gt; Multiple R-squared:  0.9597, Adjusted R-squared:  0.9487 \n#&gt; F-statistic: 87.21 on 3 and 11 DF,  p-value: 5.956e-08"
  },
  {
    "objectID": "content/01_journal/05_dag.html#part-3",
    "href": "content/01_journal/05_dag.html#part-3",
    "title": "Directed Acyclic Graphs",
    "section": "Part 3",
    "text": "Part 3\nBy observing both models, the coefficient for follow_ups is -3.3093 in model 1, and 2.1944 in model 2.\nThis maybe interpreted as for model 1, for each additional follow up call, satisfaction is decreasing by 3.3093 units holding subscription constant. Whereas for model 2, satisfaction increases 2.1944 units holding subscription constant.\nBy comparison the relation between satisfaction and follow up maybe influenced by subscription, i.e., presence of subscription levels (Premium and Premium+) has an additional impact on satisfaction beyond the effect of follow-up calls alone."
  },
  {
    "objectID": "content/01_journal/05_dag.html#part-4",
    "href": "content/01_journal/05_dag.html#part-4",
    "title": "Directed Acyclic Graphs",
    "section": "Part 4",
    "text": "Part 4\n\n# Not conditioning on subscription\ncustomer_sat_not_cond &lt;- ggplot(cust_sat, aes(x = follow_ups, y = satisfaction)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", se = FALSE)\n\n# Conditioning on subscription\ncustomer_sat_cond &lt;- ggplot(cust_sat, aes(x = follow_ups, y = satisfaction, color = subscription)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", se = FALSE) +\n  theme(legend.position = \"right\")\n\n# Plot both\ncustomer_sat_not_cond\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\ncustomer_sat_cond\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/09_iv.html#part-1",
    "href": "content/01_journal/09_iv.html#part-1",
    "title": "Instrumental Variables",
    "section": "",
    "text": "library(dplyr)\n\n#&gt; \n#&gt; Attaching package: 'dplyr'\n\n\n#&gt; The following objects are masked from 'package:stats':\n#&gt; \n#&gt;     filter, lag\n\n\n#&gt; The following objects are masked from 'package:base':\n#&gt; \n#&gt;     intersect, setdiff, setequal, union\n\nlibrary(dagitty)\nlibrary(ggdag)\n\n#&gt; \n#&gt; Attaching package: 'ggdag'\n\n\n#&gt; The following object is masked from 'package:stats':\n#&gt; \n#&gt;     filter\n\nlibrary(ggrepel)\n\n#&gt; Loading required package: ggplot2\n\ndf &lt;- readRDS(\"../../Causal_Data_Science_Data/rand_enc.rds\")\n\n# Part 1\niv_expl &lt;- dagify(\n  Y ~ D,\n  Y ~ U,\n  D ~ U,\n  D ~ Z,\n  exposure = \"D\",\n  latent = \"U\",\n  outcome = \"Y\",\n  coords = list(x = c(U = 1, D = 0, Y = 2, Z = -1),\n                y = c(U = 1, D = 0, Y = 0, Z = 0)),\n  labels = c(\"D\" = \"Used New Features\",\n             \"Y\" = \"Time Spent\",\n             \"U\" = \"Unobserved Characteristics\",\n             \"Z\" = \"Random Encouragement\")\n)\n\n# Plot the DAG\nggdag(iv_expl, text = TRUE) +\n  geom_dag_point(color = \"lightblue\") +\n  geom_dag_text(color = \"white\") +\n  geom_dag_edges(edge_color = \"white\") +\n  geom_dag_label_repel(aes(label = label)) +\n  theme(panel.background = element_rect(fill = \"black\"))"
  },
  {
    "objectID": "content/01_journal/09_iv.html#part-2",
    "href": "content/01_journal/09_iv.html#part-2",
    "title": "Instrumental Variables",
    "section": "Part 2",
    "text": "Part 2\n\n# Part 2\nmodel_biased &lt;- lm(time_spent ~ used_ftr, data = df)\nsummary(model_biased)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = time_spent ~ used_ftr, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -20.4950  -3.5393   0.0158   3.5961  20.5051 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 18.86993    0.06955   271.3   &lt;2e-16 ***\n#&gt; used_ftr    10.82269    0.10888    99.4   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 5.351 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  0.497,  Adjusted R-squared:  0.497 \n#&gt; F-statistic:  9881 on 1 and 9998 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "content/01_journal/09_iv.html#part-3",
    "href": "content/01_journal/09_iv.html#part-3",
    "title": "Instrumental Variables",
    "section": "Part 3",
    "text": "Part 3\n\nrandom encouragement is correlated with the used_ftr (positive correlation)\nrandom encouragement is not directly correlated with the time_spent which can be seen by correlation between used_ftr and time_spent and correlation between rand_enc and time_spent. Therefore IV estimation can be used.\n\n\ncor(df) %&gt;% round(2)\n\n#&gt;            rand_enc used_ftr time_spent\n#&gt; rand_enc       1.00     0.20       0.13\n#&gt; used_ftr       0.20     1.00       0.71\n#&gt; time_spent     0.13     0.71       1.00"
  },
  {
    "objectID": "content/01_journal/09_iv.html#part-4",
    "href": "content/01_journal/09_iv.html#part-4",
    "title": "Instrumental Variables",
    "section": "Part 4",
    "text": "Part 4\n\nlibrary(estimatr)\nmodel_iv &lt;- iv_robust(time_spent ~ used_ftr | rand_enc, data = df)\nsummary(model_iv)\n\n#&gt; \n#&gt; Call:\n#&gt; iv_robust(formula = time_spent ~ used_ftr | rand_enc, data = df)\n#&gt; \n#&gt; Standard error type:  HC2 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value  Pr(&gt;|t|) CI Lower CI Upper   DF\n#&gt; (Intercept)   19.312     0.2248   85.89 0.000e+00   18.872    19.75 9998\n#&gt; used_ftr       9.738     0.5353   18.19 8.716e-73    8.689    10.79 9998\n#&gt; \n#&gt; Multiple R-squared:  0.4921 ,    Adjusted R-squared:  0.492 \n#&gt; F-statistic:   331 on 1 and 9998 DF,  p-value: &lt; 2.2e-16"
  }
]